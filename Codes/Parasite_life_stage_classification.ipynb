{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d97e665",
   "metadata": {},
   "source": [
    "# Load GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba0dd37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\" \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b78b6b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from glob import glob \n",
    "#from skimage.io import imread #read images from files\n",
    "import os\n",
    "import cv2 as cv\n",
    "from PIL import Image\n",
    "from keras_unet_collection import models\n",
    "import matplotlib.pyplot as plt # plt show image\n",
    "import matplotlib.image as mpimg # mpimg read image\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e03cff6d",
   "metadata": {},
   "source": [
    "# Preparation of path_parasite_life_stage_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5612f740",
   "metadata": {},
   "outputs": [],
   "source": [
    "    path_parasite_life_stage_classification = 'E:/ziheng-projects/test_jerome/segmentation/data/aLatest/validation4_new/zz_test_manual/new/111_img/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5165efff",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5451632e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(444, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import np_utils\n",
    "base_tile_dir4 = path_parasite_life_stage_classification + 'red/' #path of the red class\n",
    "df4= pd.DataFrame({'path': glob(os.path.join(base_tile_dir4,'*.png'))})\n",
    "#df['id'] = df.path.map(lambda x: x.split('\\\\')[1].split(\".\")[0])\n",
    "df4['filename'] = df4.path.map(lambda x: x.split('\\\\')[1])\n",
    "df4['label']=0\n",
    "\n",
    "base_tile_dir5 = path_parasite_life_stage_classification + 'white/' #path of the white class\n",
    "df5= pd.DataFrame({'path': glob(os.path.join(base_tile_dir5,'*.png'))})\n",
    "#df['id'] = df.path.map(lambda x: x.split('\\\\')[1].split(\".\")[0])\n",
    "df5['filename'] = df5.path.map(lambda x: x.split('\\\\')[1])\n",
    "df5['label']=1\n",
    "\n",
    "\n",
    "base_tile_dir6 = path_parasite_life_stage_classification + 'yellow/' #path of the yellow class\n",
    "df6= pd.DataFrame({'path': glob(os.path.join(base_tile_dir6,'*.png'))})\n",
    "#df['id'] = df.path.map(lambda x: x.split('\\\\')[1].split(\".\")[0])\n",
    "df6['filename'] = df6.path.map(lambda x: x.split('\\\\')[1])\n",
    "df6['label']=2\n",
    "\n",
    "base_tile_dir7 = path_parasite_life_stage_classification + 'blue/' #path of the blue class\n",
    "df7= pd.DataFrame({'path': glob(os.path.join(base_tile_dir7,'*.png'))})\n",
    "#df['id'] = df.path.map(lambda x: x.split('\\\\')[1].split(\".\")[0])\n",
    "df7['filename'] = df7.path.map(lambda x: x.split('\\\\')[1])\n",
    "df7['label']=3\n",
    "\n",
    "df_val = pd.concat([df4,df5,df6,df7], ignore_index=True).reset_index()\n",
    "df_val = df_val[[\"path\", \"filename\", \"label\"]]\n",
    "\n",
    "df_val['image'] = df_val['path'].map(cv.imread)\n",
    "\n",
    "\n",
    "val_tensors = np.stack(list(df_val.image), axis = 0)\n",
    "print(val_tensors.shape)\n",
    "val_targets = np_utils.to_categorical(df_val.label, num_classes=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b1e03e",
   "metadata": {},
   "source": [
    "# Preparation of model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "544c745d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_unet_collection.layer_utils import *\n",
    "from keras_unet_collection.activations import GELU, Snake\n",
    "from keras_unet_collection.transformer_layers import patch_extract, patch_embedding\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Layer, MultiHeadAttention, LayerNormalization, Dense, Embedding\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, BatchNormalization, Activation\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import RMSprop, Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "\n",
    "def ViT_MLP(X, filter_num, activation='GELU', name='MLP'):\n",
    "    '''\n",
    "    The MLP block of ViT.\n",
    "    \n",
    "    ----------\n",
    "    Dosovitskiy, A., Beyer, L., Kolesnikov, A., Weissenborn, D., Zhai, X., Unterthiner, \n",
    "    T., Dehghani, M., Minderer, M., Heigold, G., Gelly, S. and Uszkoreit, J., 2020. \n",
    "    An image is worth 16x16 words: Transformers for image recognition at scale. \n",
    "    arXiv preprint arXiv:2010.11929.\n",
    "    \n",
    "    Input\n",
    "    ----------\n",
    "        X: the input tensor of MLP, i.e., after MSA and skip connections\n",
    "        filter_num: a list that defines the number of nodes for each MLP layer.\n",
    "                        For the last MLP layer, its number of node must equal to the dimension of key.\n",
    "        activation: activation of MLP nodes.\n",
    "        name: prefix of the created keras layers.\n",
    "        \n",
    "    Output\n",
    "    ----------\n",
    "        V: output tensor.\n",
    "    '''\n",
    "    activation_func = eval(activation)\n",
    "    \n",
    "    for i, f in enumerate(filter_num):\n",
    "        X = Dense(f, name='{}_dense_{}'.format(name, i))(X)\n",
    "        X = activation_func(name='{}_activation_{}'.format(name, i))(X)\n",
    "        \n",
    "    return X\n",
    "\n",
    "def ViT_block(V, num_heads, key_dim, filter_num_MLP, activation='GELU', name='ViT'):\n",
    "    '''\n",
    "    \n",
    "    Vision transformer (ViT) block.\n",
    "    \n",
    "    ViT_block(V, num_heads, key_dim, filter_num_MLP, activation='GELU', name='ViT')\n",
    "    \n",
    "    ----------\n",
    "    Dosovitskiy, A., Beyer, L., Kolesnikov, A., Weissenborn, D., Zhai, X., Unterthiner, \n",
    "    T., Dehghani, M., Minderer, M., Heigold, G., Gelly, S. and Uszkoreit, J., 2020. \n",
    "    An image is worth 16x16 words: Transformers for image recognition at scale. \n",
    "    arXiv preprint arXiv:2010.11929.\n",
    "    \n",
    "    Input\n",
    "    ----------\n",
    "        V: embedded input features.\n",
    "        num_heads: number of attention heads.\n",
    "        key_dim: dimension of the attention key (equals to the embeded dimensions).\n",
    "        filter_num_MLP: a list that defines the number of nodes for each MLP layer.\n",
    "                        For the last MLP layer, its number of node must equal to the dimension of key.\n",
    "        activation: activation of MLP nodes.\n",
    "        name: prefix of the created keras layers.\n",
    "        \n",
    "    Output\n",
    "    ----------\n",
    "        V: output tensor.\n",
    "    \n",
    "    '''\n",
    "    # Multiheaded self-attention (MSA)\n",
    "    V_atten = V # <--- skip\n",
    "    V_atten = LayerNormalization(name='{}_layer_norm_1'.format(name))(V_atten)\n",
    "    V_atten = MultiHeadAttention(num_heads=num_heads, key_dim=key_dim, \n",
    "                                 name='{}_atten'.format(name))(V_atten, V_atten)\n",
    "    # Skip connection\n",
    "    V_add = add([V_atten, V], name='{}_skip_1'.format(name)) # <--- skip\n",
    "    \n",
    "    # MLP\n",
    "    V_MLP = V_add # <--- skip\n",
    "    V_MLP = LayerNormalization(name='{}_layer_norm_2'.format(name))(V_MLP)\n",
    "    V_MLP = ViT_MLP(V_MLP, filter_num_MLP, activation, name='{}_mlp'.format(name))\n",
    "    # Skip connection\n",
    "    V_out = add([V_MLP, V_add], name='{}_skip_2'.format(name)) # <--- skip\n",
    "    \n",
    "    return V_out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb5d757",
   "metadata": {},
   "source": [
    "# Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0306661e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1 (Conv2D)           (None, 224, 224, 16) 448         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2 (Conv2D)           (None, 224, 224, 16) 2320        block1_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_pool (MaxPooling2D)      (None, 112, 112, 16) 0           block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv1 (Conv2D)           (None, 112, 112, 32) 4640        block1_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv2 (Conv2D)           (None, 112, 112, 32) 9248        block2_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)      (None, 56, 56, 32)   0           block2_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv1 (Conv2D)           (None, 56, 56, 64)   18496       block2_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv2 (Conv2D)           (None, 56, 56, 64)   36928       block3_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)      (None, 28, 28, 64)   0           block3_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv1 (Conv2D)           (None, 28, 28, 128)  73856       block3_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv2 (Conv2D)           (None, 28, 28, 128)  147584      block4_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)      (None, 14, 14, 128)  0           block4_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv1 (Conv2D)           (None, 14, 14, 256)  295168      block4_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv2 (Conv2D)           (None, 14, 14, 256)  590080      block5_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_pool (MaxPooling2D)      (None, 7, 7, 256)    0           block5_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "patch_extract (patch_extract)   (None, 49, 256)      0           block5_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "patch_embedding (patch_embeddin (None, 49, 128)      39168       patch_extract[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "TransLightNet_ViT_0_layer_norm_ (None, 49, 128)      256         patch_embedding[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "TransLightNet_ViT_0_atten (Mult (None, 49, 128)      791168      TransLightNet_ViT_0_layer_norm_1[\n",
      "                                                                 TransLightNet_ViT_0_layer_norm_1[\n",
      "__________________________________________________________________________________________________\n",
      "TransLightNet_ViT_0_skip_1 (Add (None, 49, 128)      0           TransLightNet_ViT_0_atten[0][0]  \n",
      "                                                                 patch_embedding[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "TransLightNet_ViT_0_layer_norm_ (None, 49, 128)      256         TransLightNet_ViT_0_skip_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "TransLightNet_ViT_0_mlp_dense_0 (None, 49, 32)       4128        TransLightNet_ViT_0_layer_norm_2[\n",
      "__________________________________________________________________________________________________\n",
      "TransLightNet_ViT_0_mlp_activat (None, 49, 32)       0           TransLightNet_ViT_0_mlp_dense_0[0\n",
      "__________________________________________________________________________________________________\n",
      "TransLightNet_ViT_0_mlp_dense_1 (None, 49, 128)      4224        TransLightNet_ViT_0_mlp_activatio\n",
      "__________________________________________________________________________________________________\n",
      "TransLightNet_ViT_0_mlp_activat (None, 49, 128)      0           TransLightNet_ViT_0_mlp_dense_1[0\n",
      "__________________________________________________________________________________________________\n",
      "TransLightNet_ViT_0_skip_2 (Add (None, 49, 128)      0           TransLightNet_ViT_0_mlp_activatio\n",
      "                                                                 TransLightNet_ViT_0_skip_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "TransLightNet_ViT_1_layer_norm_ (None, 49, 128)      256         TransLightNet_ViT_0_skip_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "TransLightNet_ViT_1_atten (Mult (None, 49, 128)      791168      TransLightNet_ViT_1_layer_norm_1[\n",
      "                                                                 TransLightNet_ViT_1_layer_norm_1[\n",
      "__________________________________________________________________________________________________\n",
      "TransLightNet_ViT_1_skip_1 (Add (None, 49, 128)      0           TransLightNet_ViT_1_atten[0][0]  \n",
      "                                                                 TransLightNet_ViT_0_skip_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "TransLightNet_ViT_1_layer_norm_ (None, 49, 128)      256         TransLightNet_ViT_1_skip_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "TransLightNet_ViT_1_mlp_dense_0 (None, 49, 32)       4128        TransLightNet_ViT_1_layer_norm_2[\n",
      "__________________________________________________________________________________________________\n",
      "TransLightNet_ViT_1_mlp_activat (None, 49, 32)       0           TransLightNet_ViT_1_mlp_dense_0[0\n",
      "__________________________________________________________________________________________________\n",
      "TransLightNet_ViT_1_mlp_dense_1 (None, 49, 128)      4224        TransLightNet_ViT_1_mlp_activatio\n",
      "__________________________________________________________________________________________________\n",
      "TransLightNet_ViT_1_mlp_activat (None, 49, 128)      0           TransLightNet_ViT_1_mlp_dense_1[0\n",
      "__________________________________________________________________________________________________\n",
      "TransLightNet_ViT_1_skip_2 (Add (None, 49, 128)      0           TransLightNet_ViT_1_mlp_activatio\n",
      "                                                                 TransLightNet_ViT_1_skip_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "TransLightNet_ViT_2_layer_norm_ (None, 49, 128)      256         TransLightNet_ViT_1_skip_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "TransLightNet_ViT_2_atten (Mult (None, 49, 128)      791168      TransLightNet_ViT_2_layer_norm_1[\n",
      "                                                                 TransLightNet_ViT_2_layer_norm_1[\n",
      "__________________________________________________________________________________________________\n",
      "TransLightNet_ViT_2_skip_1 (Add (None, 49, 128)      0           TransLightNet_ViT_2_atten[0][0]  \n",
      "                                                                 TransLightNet_ViT_1_skip_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "TransLightNet_ViT_2_layer_norm_ (None, 49, 128)      256         TransLightNet_ViT_2_skip_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "TransLightNet_ViT_2_mlp_dense_0 (None, 49, 32)       4128        TransLightNet_ViT_2_layer_norm_2[\n",
      "__________________________________________________________________________________________________\n",
      "TransLightNet_ViT_2_mlp_activat (None, 49, 32)       0           TransLightNet_ViT_2_mlp_dense_0[0\n",
      "__________________________________________________________________________________________________\n",
      "TransLightNet_ViT_2_mlp_dense_1 (None, 49, 128)      4224        TransLightNet_ViT_2_mlp_activatio\n",
      "__________________________________________________________________________________________________\n",
      "TransLightNet_ViT_2_mlp_activat (None, 49, 128)      0           TransLightNet_ViT_2_mlp_dense_1[0\n",
      "__________________________________________________________________________________________________\n",
      "TransLightNet_ViT_2_skip_2 (Add (None, 49, 128)      0           TransLightNet_ViT_2_mlp_activatio\n",
      "                                                                 TransLightNet_ViT_2_skip_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "TransLightNet_ViT_3_layer_norm_ (None, 49, 128)      256         TransLightNet_ViT_2_skip_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "TransLightNet_ViT_3_atten (Mult (None, 49, 128)      791168      TransLightNet_ViT_3_layer_norm_1[\n",
      "                                                                 TransLightNet_ViT_3_layer_norm_1[\n",
      "__________________________________________________________________________________________________\n",
      "TransLightNet_ViT_3_skip_1 (Add (None, 49, 128)      0           TransLightNet_ViT_3_atten[0][0]  \n",
      "                                                                 TransLightNet_ViT_2_skip_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "TransLightNet_ViT_3_layer_norm_ (None, 49, 128)      256         TransLightNet_ViT_3_skip_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "TransLightNet_ViT_3_mlp_dense_0 (None, 49, 32)       4128        TransLightNet_ViT_3_layer_norm_2[\n",
      "__________________________________________________________________________________________________\n",
      "TransLightNet_ViT_3_mlp_activat (None, 49, 32)       0           TransLightNet_ViT_3_mlp_dense_0[0\n",
      "__________________________________________________________________________________________________\n",
      "TransLightNet_ViT_3_mlp_dense_1 (None, 49, 128)      4224        TransLightNet_ViT_3_mlp_activatio\n",
      "__________________________________________________________________________________________________\n",
      "TransLightNet_ViT_3_mlp_activat (None, 49, 128)      0           TransLightNet_ViT_3_mlp_dense_1[0\n",
      "__________________________________________________________________________________________________\n",
      "TransLightNet_ViT_3_skip_2 (Add (None, 49, 128)      0           TransLightNet_ViT_3_mlp_activatio\n",
      "                                                                 TransLightNet_ViT_3_skip_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "TransLightNet_ViT_4_layer_norm_ (None, 49, 128)      256         TransLightNet_ViT_3_skip_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "TransLightNet_ViT_4_atten (Mult (None, 49, 128)      791168      TransLightNet_ViT_4_layer_norm_1[\n",
      "                                                                 TransLightNet_ViT_4_layer_norm_1[\n",
      "__________________________________________________________________________________________________\n",
      "TransLightNet_ViT_4_skip_1 (Add (None, 49, 128)      0           TransLightNet_ViT_4_atten[0][0]  \n",
      "                                                                 TransLightNet_ViT_3_skip_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "TransLightNet_ViT_4_layer_norm_ (None, 49, 128)      256         TransLightNet_ViT_4_skip_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "TransLightNet_ViT_4_mlp_dense_0 (None, 49, 32)       4128        TransLightNet_ViT_4_layer_norm_2[\n",
      "__________________________________________________________________________________________________\n",
      "TransLightNet_ViT_4_mlp_activat (None, 49, 32)       0           TransLightNet_ViT_4_mlp_dense_0[0\n",
      "__________________________________________________________________________________________________\n",
      "TransLightNet_ViT_4_mlp_dense_1 (None, 49, 128)      4224        TransLightNet_ViT_4_mlp_activatio\n",
      "__________________________________________________________________________________________________\n",
      "TransLightNet_ViT_4_mlp_activat (None, 49, 128)      0           TransLightNet_ViT_4_mlp_dense_1[0\n",
      "__________________________________________________________________________________________________\n",
      "TransLightNet_ViT_4_skip_2 (Add (None, 49, 128)      0           TransLightNet_ViT_4_mlp_activatio\n",
      "                                                                 TransLightNet_ViT_4_skip_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "TransLightNet_ViT_5_layer_norm_ (None, 49, 128)      256         TransLightNet_ViT_4_skip_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "TransLightNet_ViT_5_atten (Mult (None, 49, 128)      791168      TransLightNet_ViT_5_layer_norm_1[\n",
      "                                                                 TransLightNet_ViT_5_layer_norm_1[\n",
      "__________________________________________________________________________________________________\n",
      "TransLightNet_ViT_5_skip_1 (Add (None, 49, 128)      0           TransLightNet_ViT_5_atten[0][0]  \n",
      "                                                                 TransLightNet_ViT_4_skip_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "TransLightNet_ViT_5_layer_norm_ (None, 49, 128)      256         TransLightNet_ViT_5_skip_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "TransLightNet_ViT_5_mlp_dense_0 (None, 49, 32)       4128        TransLightNet_ViT_5_layer_norm_2[\n",
      "__________________________________________________________________________________________________\n",
      "TransLightNet_ViT_5_mlp_activat (None, 49, 32)       0           TransLightNet_ViT_5_mlp_dense_0[0\n",
      "__________________________________________________________________________________________________\n",
      "TransLightNet_ViT_5_mlp_dense_1 (None, 49, 128)      4224        TransLightNet_ViT_5_mlp_activatio\n",
      "__________________________________________________________________________________________________\n",
      "TransLightNet_ViT_5_mlp_activat (None, 49, 128)      0           TransLightNet_ViT_5_mlp_dense_1[0\n",
      "__________________________________________________________________________________________________\n",
      "TransLightNet_ViT_5_skip_2 (Add (None, 49, 128)      0           TransLightNet_ViT_5_mlp_activatio\n",
      "                                                                 TransLightNet_ViT_5_skip_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 6272)         0           TransLightNet_ViT_5_skip_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "fc1 (Dense)                     (None, 256)          1605888     flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 256)          0           fc1[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "predictions (Dense)             (None, 4)            1028        dropout[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 7,625,044\n",
      "Trainable params: 7,625,044\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_shape = (224, 224, 3)\n",
    "img_input = Input(shape=input_shape)\n",
    "\n",
    "# Block 1\n",
    "x = Conv2D(16, (3, 3), activation='relu', padding='same', name='block1_conv1')(img_input)\n",
    "x = Conv2D(16, (3, 3), activation='relu', padding='same', name='block1_conv2')(x)\n",
    "x = MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool')(x)\n",
    "\n",
    "# Block 2\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same', name='block2_conv1')(x)\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same', name='block2_conv2')(x)\n",
    "x = MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool')(x)\n",
    "\n",
    "# Block 3\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block3_conv1')(x)\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block3_conv2')(x)\n",
    "x = MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool')(x)\n",
    "\n",
    "# Block 4\n",
    "x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block4_conv1')(x)\n",
    "x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block4_conv2')(x)\n",
    "x = MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool')(x)\n",
    "\n",
    "# Block 5\n",
    "x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block5_conv1')(x)\n",
    "x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block5_conv2')(x)\n",
    "x = MaxPooling2D((2, 2), strides=(2, 2), name='block5_pool')(x)\n",
    "\n",
    "\n",
    "\n",
    "patch_size=1\n",
    "x = patch_extract((patch_size, patch_size))(x)\n",
    "x = patch_embedding(49, 128)(x)\n",
    "filter_num_MLP = [32, 128]\n",
    "num_transformer=6\n",
    "name='TransLightNet'\n",
    "for i in range(num_transformer):\n",
    "    x = ViT_block(x, 12, 128, filter_num_MLP, activation='GELU',\n",
    "                 name='{}_ViT_{}'.format(name, i))\n",
    "x = Flatten()(x)  \n",
    "x = Dense(256, activation='elu', name='fc1')(x)  \n",
    "x = Dropout(0.5)(x) \n",
    "\n",
    "\n",
    "\n",
    "predictions = Dense(4, activation='softmax', name='predictions')(x) \n",
    "model = Model(img_input, predictions)  \n",
    "model.compile(Adam(0.0001), loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8ec8e9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 8s 86ms/step - loss: 0.1696 - accuracy: 0.9550\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.16962604224681854, 0.954954981803894]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Download model 'Parasite life stage classification.hdf5' and put it inside the path_parasite_life_stage_classification \n",
    "model.load_weights(path_parasite_life_stage_classification + 'Parasite life stage classification.hdf5')\n",
    "model.evaluate(val_tensors, val_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55623bbe",
   "metadata": {},
   "source": [
    "# Confusion metrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1cb6d9b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[108   0   3   0]\n",
      " [  0 103   6   2]\n",
      " [  2   6 103   0]\n",
      " [  0   0   1 110]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy_score: 0.955\n",
      "Precision_score: 0.955\n",
      "Recall: 0.955\n",
      "F1_score: 0.955\n"
     ]
    }
   ],
   "source": [
    "#class label 0\n",
    "base_tile_dir = base_tile_dir4\n",
    "test_df = pd.DataFrame({'path': glob(os.path.join(base_tile_dir,'*.png'))})\n",
    "test_df['filename'] = test_df.path.map(lambda x: x.split('\\\\')[1])\n",
    "test_df.head(5)\n",
    "\n",
    "test_df['image'] = test_df['path'].map(cv.imread)\n",
    "test_images = np.stack(test_df.image, axis = 0)\n",
    "test_images.shape\n",
    "\n",
    "predicted_labels0 =  [model.predict(np.expand_dims(tensor, axis=0))[0].argsort()[-1] for tensor in test_images]\n",
    "\n",
    "y_true0 = [0 for i in range(111)]\n",
    "##########################################\n",
    "#class label 1\n",
    "base_tile_dir = base_tile_dir5\n",
    "test_df = pd.DataFrame({'path': glob(os.path.join(base_tile_dir,'*.png'))})\n",
    "test_df['filename'] = test_df.path.map(lambda x: x.split('\\\\')[1])\n",
    "test_df.head(5)\n",
    "\n",
    "test_df['image'] = test_df['path'].map(cv.imread)\n",
    "test_images = np.stack(test_df.image, axis = 0)\n",
    "test_images.shape\n",
    "\n",
    "predicted_labels1 =  [model.predict(np.expand_dims(tensor, axis=0))[0].argsort()[-1] for tensor in test_images]\n",
    "y_true1 = [1 for i in range(111)]\n",
    "##########################################\n",
    "#class label 2\n",
    "base_tile_dir = base_tile_dir6\n",
    "test_df = pd.DataFrame({'path': glob(os.path.join(base_tile_dir,'*.png'))})\n",
    "test_df['filename'] = test_df.path.map(lambda x: x.split('\\\\')[1])\n",
    "test_df.head(5)\n",
    "\n",
    "test_df['image'] = test_df['path'].map(cv.imread)\n",
    "test_images = np.stack(test_df.image, axis = 0)\n",
    "test_images.shape\n",
    "\n",
    "predicted_labels2 =  [model.predict(np.expand_dims(tensor, axis=0))[0].argsort()[-1] for tensor in test_images]\n",
    "y_true2 = [2 for i in range(111)]\n",
    "##########################################\n",
    "#class label 3\n",
    "base_tile_dir = base_tile_dir7\n",
    "test_df = pd.DataFrame({'path': glob(os.path.join(base_tile_dir,'*.png'))})\n",
    "test_df['filename'] = test_df.path.map(lambda x: x.split('\\\\')[1])\n",
    "test_df.head(5)\n",
    "\n",
    "test_df['image'] = test_df['path'].map(cv.imread)\n",
    "test_images = np.stack(test_df.image, axis = 0)\n",
    "#test_images = np.reshape(test_images,test_images.shape+(1,))\n",
    "test_images.shape\n",
    "\n",
    "predicted_labels3 =  [model.predict(np.expand_dims(tensor, axis=0))[0].argsort()[-1] for tensor in test_images]\n",
    "y_true3 = [3 for i in range(111)]\n",
    "\n",
    "###############################################################################################################\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "#from glob import glob \n",
    "y_true=y_true0+y_true1+y_true2+y_true3\n",
    "y_pred=predicted_labels0+predicted_labels1+predicted_labels2+predicted_labels3\n",
    "multiclass=confusion_matrix(y_true, y_pred)\n",
    "print(multiclass)\n",
    "\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "fig, ax = plot_confusion_matrix(conf_mat=multiclass, show_absolute=True,  show_normed=True)\n",
    "plt.show()\n",
    "\n",
    "#accuracy_score, precision_score, recall_score, f1_score, \n",
    "print('Accuracy_score: %.3f' % accuracy_score(y_true, y_pred))\n",
    "print('Precision_score: %.3f' % precision_score(y_true, y_pred,average='weighted'))\n",
    "print('Recall: %.3f' % recall_score(y_true, y_pred,average='weighted'))\n",
    "print('F1_score: %.3f' % f1_score(y_true, y_pred,average='weighted'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow-GPU-2.5.0",
   "language": "python",
   "name": "tf2.5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
